{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "994e8258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (100000, 9)\n",
      "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
      "0  Female  80.0             0              1           never  25.19   \n",
      "1  Female  54.0             0              0         No Info  27.32   \n",
      "2    Male  28.0             0              0           never  27.32   \n",
      "3  Female  36.0             0              0         current  23.45   \n",
      "4    Male  76.0             1              1         current  20.14   \n",
      "\n",
      "   HbA1c_level  blood_glucose_level  diabetes  \n",
      "0          6.6                  140         0  \n",
      "1          6.6                   80         0  \n",
      "2          5.7                  158         0  \n",
      "3          5.0                  155         0  \n",
      "4          4.8                  155         0  \n",
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n",
      "Train shape: (80000, 13)  Test shape: (20000, 13)\n",
      "Positive rate in train: 0.085\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Target & features\n",
    "target = 'diabetes'\n",
    "y = df[target].astype(int)\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "# One-hot for categoricals (simple style from course)\n",
    "cat_cols = ['gender', 'smoking_history']\n",
    "X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n",
    "print(\"Positive rate in train:\", y_train.mean().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e60675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression (no grid) ===\n",
      "Accuracy: 0.88885\n",
      "Precision: 0.42656557146868856\n",
      "Recall: 0.8935294117647059\n",
      "F1: 0.5774567572704808\n",
      "ROC-AUC: 0.9629510928961749\n",
      "Confusion matrix:\n",
      " [[16258  2042]\n",
      " [  181  1519]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94     18300\n",
      "           1       0.43      0.89      0.58      1700\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.71      0.89      0.76     20000\n",
      "weighted avg       0.94      0.89      0.91     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "log_clf = LogisticRegression(max_iter=2000, class_weight='balanced', solver='lbfgs', random_state=42)\n",
    "log_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_clf.predict(X_test)\n",
    "y_proba = log_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Logistic Regression (no grid) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f16a1e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(24745) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(24746) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(24747) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(24748) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(24749) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(24750) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(24751) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(24752) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(24753) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(24754) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression (Grid Search) ===\n",
      "Best params: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best CV F1: 0.5696836730733158\n",
      "Accuracy: 0.88885\n",
      "Precision: 0.4266067920291889\n",
      "Recall: 0.8941176470588236\n",
      "F1: 0.5776173285198556\n",
      "ROC-AUC: 0.9629591288974607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_base = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 3, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "gs_log = GridSearchCV(\n",
    "    estimator=log_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gs_log.fit(X_train, y_train)\n",
    "\n",
    "best_log = gs_log.best_estimator_\n",
    "y_pred = best_log.predict(X_test)\n",
    "y_proba = best_log.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Logistic Regression (Grid Search) ===\")\n",
    "print(\"Best params:\", gs_log.best_params_)\n",
    "print(\"Best CV F1:\", gs_log.best_score_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550cb0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVM (no grid) ===\n",
      "Accuracy: 0.89625\n",
      "Precision: 0.446167097329888\n",
      "Recall: 0.9141176470588235\n",
      "F1: 0.5996527107852595\n",
      "ROC-AUC: 0.9643806975249116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "svm_clf = SVC(kernel='rbf', C=1.0, gamma='scale', class_weight='balanced',\n",
    "              probability=True, random_state=42)\n",
    "svm_clf.fit(X_train_s, y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test_s)\n",
    "y_proba = svm_clf.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "print(\"=== SVM (no grid) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d0c719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "=== SVM (Grid Search, fast) ===\n",
      "Best params: {'C': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best CV F1: 0.5949629880609021\n",
      "Accuracy: 0.89735\n",
      "Precision: 0.44870677128741643\n",
      "Recall: 0.908235294117647\n",
      "F1: 0.6006613499319199\n",
      "ROC-AUC: 0.9672072645451623\n"
     ]
    }
   ],
   "source": [
    "svm_base = SVC(class_weight='balanced',\n",
    "               probability=False,         # turn OFF for search\n",
    "               cache_size=1000,\n",
    "               random_state=42)\n",
    "\n",
    "svm_grid = {\n",
    "    'kernel': ['rbf'],                   # keep only rbf\n",
    "    'C': [0.5, 1, 3],\n",
    "    'gamma': ['scale', 0.05]             # small grid\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(\n",
    "    estimator=svm_base,\n",
    "    param_grid=svm_grid,\n",
    "    scoring='f1',\n",
    "    cv=3,                                # fewer folds\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gs_svm.fit(X_train_s, y_train)\n",
    "print(\"=== SVM (Grid Search, fast) ===\")\n",
    "print(\"Best params:\", gs_svm.best_params_)\n",
    "print(\"Best CV F1:\", gs_svm.best_score_)\n",
    "\n",
    "# Refit once with probabilities for ROC-AUC/report\n",
    "best_params = gs_svm.best_params_.copy()\n",
    "svm_final = SVC(class_weight='balanced',\n",
    "                probability=True,        # turn ON only once\n",
    "                cache_size=1000,\n",
    "                random_state=42,\n",
    "                **best_params)\n",
    "\n",
    "svm_final.fit(X_train_s, y_train)\n",
    "y_pred  = svm_final.predict(X_test_s)\n",
    "y_proba = svm_final.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c98b1649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost (no grid) ===\n",
      "Accuracy: 0.9722\n",
      "Precision: 0.9766666666666667\n",
      "Recall: 0.6894117647058824\n",
      "F1: 0.8082758620689655\n",
      "ROC-AUC: 0.9797781742205078\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "y_proba = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== XGBoost (no grid) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b6a216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(25710) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(25711) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(25712) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(25713) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(25714) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(25715) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(25716) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(25717) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(25718) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(25719) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost (Grid Search) ===\n",
      "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best CV F1: 0.8072521821520736\n",
      "Accuracy: 0.972\n",
      "Precision: 0.9765886287625418\n",
      "Recall: 0.6870588235294117\n",
      "F1: 0.8066298342541437\n",
      "ROC-AUC: 0.9795537929926068\n"
     ]
    }
   ],
   "source": [
    "xgb_base = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gs_xgb = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=xgb_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gs_xgb.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = gs_xgb.best_estimator_\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "y_proba = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== XGBoost (Grid Search) ===\")\n",
    "print(\"Best params:\", gs_xgb.best_params_)\n",
    "print(\"Best CV F1:\", gs_xgb.best_score_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
